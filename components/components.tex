\section{Core components}

\subsection{Updated pipeline debugging system}

\assign{Simon}

The debugging system must be both reasonably powerful and easy to use.
It should also be obvious from help/doc strings how to turn on debugging.
There is a tradeoff between granularity and usability.

The recommendation is that the debugging system be simplified to be configurable at the task level.
Debugging is turned on via a config parameter.
This allows for single sub-tasks to turn on debugging independently.
In practice this means that statements like \texttt{if lsstDebug:} would turn into \texttt{if self.config.debug}.

This brings up the obvious issue that free functions/non-task methods called in the \texttt{run} method of a task do not necessarily have the debugging flag passed into them.
It becomes the responsibility of the implementer to pass \texttt{self.config.debug} into methods that have debug functionality.

Derived from \S\ref{sec:design:debug}.

i.e. redesigned \texttt{lsstDebug}.

\subsection{Logging}

\assign{Simon}

Logging is an important aspect of running large data processing.
It is also integral to quality assessment as the logging information provides important contextual information when inspecting data for quality issues.
Specifically, log messages presenting information about the processing: e.g. PSF width, number of stars used in a model fit, can indicate problems with the algorithmic behavior or input data.
Logging also provides information about potential causes for unexpected termination including exit codes and exeptions.

While logs can be straightforward to parse when only a small number of concurrent processes are being used, they quickly become harder to understand as the number of processes increases.

The logging component has the following attributes:
\begin{itemize}
\item Configurable for logging granularity. For example, \texttt{INFO}, \texttt{WARN}, \texttt{ERROR}.
\item Trivial to retrieve time ordered logs for a thread.
\item Possible to retrieve logs, exit status, or exceptions for threads ending in an unexpected state.
\item Possible to retrieve enough information to rerun the data units that were unprocessed because of processes ending in unexpected state.  KSK: perhaps this is solved by the provenance system.
\item Searchable per process for regexp and timestamp.
\end{itemize}

Derived from \S\ref{sec:design:debug}.

\subsection{Capability for developers to run pipelines at scale}

\assign{Simon}

I believe we aggreed that if the logging system and provenance system are sufficient to meet recommendations, this aspect is essentially a solved problem.

I do think that it also depends on the orchestration layer, but I don't think that can be in the scope of this group.

Derived from \S\ref{sec:design:logging}.

\subsection{Guidance on visualization}

\assign{Simon}
We decided that this section should first be seeded with contexts for visualization. We can then go through and give specific guidance.

Contexts:
\begin{itemize}
\item Notebooks in-line: matplotlib-ish
\item Dashboard like visualization: health status (grafana?)
\item Pipelines debugging visualization: both persisted PNGs and pop up vis
\item Purpose built QA visualization: Like the multisky plot from \texttt{qa\_explorer}
\item Exploratory: Single plots with interactivity, including zoom and pan
\item Linked plots: Interaction in one frame causes chnge of state in another plot
\item Image visualization: (covered elsewhere)
\item Publication plotting
\item Static plots for reports
\item Plotting from a non-notebook interactive setting
\item Rendering of cached time series: SQuaSH
\end{itemize}

Derived from \S\ref{sec:design:vis}.

We're requesting a set of guidelines for developers here, not a new framework
--- but that's still a concrete deliverable (it's just documentation, rather
than code). We might suggest that these guidelines be developed by a new WG,
per Simon's
suggestion\footnote{\url{https://confluence.lsstcorp.org/display/DM/Pipeline+Debugging+Design}}.

\subsection{Image viewer}

\assign{Trey}

Derived from \S\ref{sec:design:debug}.

As of 2018-06-12 we haven't converged on a solid recommendation here.

Key considerations:

\begin{itemize}

  \item{Firefly is the annointed solution being provided by DM to external
  stakeholders (commissioning, operations, etc). It feels right to everybody
  that we should be dogfooding it, and also benefitting from development being
  carried out for those stakeholders.}

  \item{Currently, Firefly is unappealing to developers (primarily, I think,
  because of slowness of user interface, and perhaps also due to installation
  issues). Can we resolve these issues?}

  \item{We'd want to support visualization in a number of different
  environments, for e.g.:

    \begin{itemize}

      \item{Inside a Jupyter notebook;}
      \item{As a standalone tool, \`a la DS9;}
      \item{Embedded in a \gls{dashboard}, \`a la JS9, Aladin-Lite, etc.}

    \end{itemize}
  }

  \item{Do we lose flexibility by mandating the use of a backend-agnostic API
  (\texttt{afwDisplay}) rather than going ``all-in'' on e.g. a custom Firefly
  interface?}

  \item{We'll need to do full focal plane visualization, which none(?) of the
  current tools support well.}

\end{itemize}

Options include:

\begin{itemize}

  \item{Do nothing; continue as we are, which means most people will use DS9
  and a few will drift to Firefly as commissioning ramps up.}

  \item{Issue some sort of edict that pipelines developers have to use
  Firefly.}

  \item{Encourage the use of some other tool (Ginga?) instead of or as well as
  some of the above.}

  \item{Probably others.}

\end{itemize}

Sounds like we need somebody from the QAWG to actually write some requirements
--- or a wishlist set of features we want --- here.

\subsection{Catalog visualization tools}

\assign{Lauren}

Derived from \S\ref{sec:design:debug}.

For visualizing bigger-than-memory catalogs. May include e.g. the capability
to spin up Dask clusters on demand, combined with
Holoviews/Datashader/whatever. Somebody who knows about this stuff needs to
write a summary...

\subsection{Provenance}

\assign{Hsin-Fang}

Derived from \S\ref{sec:design:debug}.

This section should note:

\begin{itemize}

  \item{That provenance is an immediate issue impacting QA work, so a solution
  is a priority;}

  \item{Some requirements as to the granularity at which provenance tracking
  is necessary for QA.}

\end{itemize}

\subsection{Documentation content updates}
\label{sec:comp:doc}

Derived from \S\ref{sec:design:test}.

\assign{John}

\begin{itemize}

  \item{Clearer guidance on unit tests.}
  \item{Clearer guidance on code review, with requirements for test coverage
  etc.}

\end{itemize}

\subsection{Testing for documentation}

Derived from \S\ref{sec:design:test}.

\assign{John}

\begin{itemize}

  \item{Examples.}

\end{itemize}

\subsection{CI system updates}

Derived from \S\ref{sec:design:test}.

\assign{John}

\begin{itemize}

  \item{Test coverage.}
  \item{Tighter control of the environment.}
  \item{Better notifications.}
  \item{Better descriptions of which jobs do what.}
  \item{Clear description of what Developers are required to do before merging
  to master (see also \S\ref{sec:comp:doc}).}

\end{itemize}


\subsection{Metrics Dashboard / SQuaSH}

Derived from \S\ref{sec:design:test}.

\assign{Angelo}

Broadly as current SQuaSH, but to track:

\begin{itemize}

  \item{Code execution time.}
  \item{Test coverage?}
  \item{Notifications of regressions.}

\end{itemize}

\subsection{Standard format dataset package}
\label{sec:comp:lfs-dataset}

Derived from \S\ref{sec:design:test}.

\assign{Hsin-Fang}

\subsection{Standard test package design}

Derived from \S\ref{sec:design:test}.

\assign{Hsin-Fang}

Should address the union of lsst\_dm\_stack\_demo, ci\_hsc, validate\_drp use
cases.

\subsection{Updates to guidelines for GPFS-based dataset storage}
\label{sec:comp:gpfs-dataset}
