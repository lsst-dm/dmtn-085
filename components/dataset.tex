\subsection{Standard format dataset package}
\label{sec:comp:dataset}

Derived from \S\ref{sec:design:test}.

\assign{Hsin-Fang}

The key considerations and motivations to standardize test datasets
in the construction phase include:

\begin{itemize}

\item{Developers would like low-friction access to test datasets.
A central location where developers can look up what has been curated
is desired.}

\item{Developers would like datasets at multiple scales and
representative of various data quality and observing conditions.
The properties of these datasets much be well understood.}

\item{Besides raw (unprocessed) data, intermediate and final data
products from various stages of pipeline processing are wanted.
They facilitiate testing of algorithms which are only relevant to
later parts of the pipeline or analysis codes without the need of
regenerating the products.}

\item{Datasets require continuing maintenance. Data products based
on a recent software release are usually wanted.}

\end{itemize}


The standard format of a dataset package is a ready-to-use Butler
repository and follows the format of a Butler repository as defined
in its corresponding obs package.  The format is configurable by
design, however, it is tied to the codes in the stack, so can change
from a software stack version to another.  Besides implementations
in the obs packages and Butler, other evolvement in the software
stack, such as handling of calibration data and reference catalog,
can also make a once-working repository incompatible.  Therefore,
maintenance is occassionally needed to ensure the usability of a
dataset package\footnote{At the time of writing, our test datasets include
the following: afwdata, ap\_verify\_hits2015, testdata\_cfht,
testdata\_deblender, testdata\_decam, testdata\_jointcal,
testdata\_lsstSim, testdata\_subaru, qserv\_testdata,
validation\_data\_cfht.  validation\_data\_decam, validation\_data\_hsc,
/datasets/auxTel, /datasets/comCam, /datasets/ctio0m9, /datasets/lsstCam,
/datasets/decam /datasets/des\_sn, /datasets/hsc, /datasets/refcats,
/datasets/sdss, /datasets/gapon}.

\begin{recommendation}
    {rec:dataset:owner}
    {Each stored dataset---whether it be stored on \gls{gpfs}, GitHub, or
    elsewhere---should have an explicitly named product owner.}
Product owners are responsible for ensuring that the content and
use cases of the datasets are well described and compatible with
recent stack versions.  The owner of a dataset can typically be the
team with immediate use cases and knowledge of its camera package.
\end{recommendation}

The Obs Pkg WG (\jira{RFC-393}) is charged to re-design and refactor
the obs packages for maintainability and extensibility. We suggest
the Obs Pkg WG take into considerations in their design to mitigate
the close tie between a Butler repository and its obs package
implmentations, as well as adopt a common structure across different
cameras when possible.  After the refactoring, the obs packages
shall rarely change so the dataset format will be more stable.  The
QAWG recommends prioritise the Obs Pkg WG.

In some cases, a dataset pacakge may contain additional data that are not
tenable in the format of a Butler repository. We recommend following the
format as described in DM Developer Guide Common Dataset Organization
and Policy \footnote{\url{https://developer.lsst.io/services/datasets.html}}
and update the policy as needed.

As for the storage of test datasets, we consider any test dataset
package being either small or large, based on its size and use cases.
The QAWG's recommendations are as follows.

\begin{itemize}
  \item \textbf{Storage of small datasets}

  We consider small datasets as those smaller than around 100 GB
  and comfortably operatable as a Git LFS repository. They are
  carefully selected to meet specific use cases. The use cases of
  small datasets include

  \begin{itemize}
    \item{as input test data in CI jobs in the DM Jenkins system
          (\S\ref{sec:comp:ci});}
    \item{as example data in documentations, demos, and tutorials.}
  \end{itemize}

  To meet their needs, we recommend them

  \begin{itemize}
    \item{packaged as EUPS products;}
    \item{made publicly available on GitHub;}
    \item{stored as Git LFS repositories as needed;}
    \item{tagged their versions with the DM software releases;}
    \item{documented clearly its use cases and named product owner for each dataset;}
  \end{itemize}

  \item \textbf{Storage of large datasets}

  We consider large datasets as those larger than around 100 GB and
  hence transferring over network takes longer than an hour typically.
  They can contain edge cases that have not been identified to form
  specific small test datasets, or for use cases in which data
  volume is important.  We recommend them

  \begin{itemize}
    \item{made available on LSST development machines (currently on GPFS);}
    \item{usable and shared by team members;}
    \item{protected under a disaster recovery policy;}
    \item{documented clearly its use cases and named product owner for each dataset;}
  \end{itemize}

\end{itemize}
