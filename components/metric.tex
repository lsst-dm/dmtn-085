\subsection{Metric collection \& tracking}
\label{sec:comp:metric}

This section is derived from \S\S\ref{sec:design:drill} and \ref{sec:design:test:metrics}.

We note that metrics describing pipeline execution may be considered in two separate --- but related --- contexts.
In some cases, we care simply about the absolute value of some metric: is the performance ``good enough''?
Does it satisfy a requirement?
In other circumstances, we might wish to keep track of a metric value as a time series: does performance change with time?
Can we identify changesets which have introduced regressions (or improvements!)?

We note further that metrics values might be calculated in a number of different contexts.
For example:

\begin{itemize}

  \item{Some metrics refer to characteristics of pipeline execution, like execution time, which \emph{by definition} must be recorded during execution or they are lost\footnote{Of course, it is not a requirement that they by recorded by a dedicated metric tracking system; one could imagine recording execution time by simply recording a log message, and then later parsing log outputs to retrieve it}.}

  \item{Others may only be calculated from intermediate data products, which would not normally be stored for posterity. These must be calculated before those intermediate products are removed.}

  \item{Finally, some are calculated from final science data products, and hence may be calculated at any time after pipeline execution.}

\end{itemize}

\subsubsection{Metric definition and calculation}
\label{sec:comp:metric:define}

The author of pipeline code can, of course, simply print to screen (or to log) a message containing some quantity that they have calculated on the fly during the execution of their code.
This is low overhead and trivial to implement.
It may be combined with the debugging system (\S\ref{sec:comp:debug}) to provide a rich set of diagnostics when the code is executing.
We suggest that there is no advantage to attempting to force some new framework onto developers operating in this mode.

However, at the level of long-term monitoring of pipeline performance, and especially at the level of requirements verification, we suggest that having a standardized, code-based definition of metrics is essential to enable clear and unambiguous comparison of results.
The SQuaRE team has developed the \texttt{lsst.verify.metrics}\footnote{\url{https://github.com/lsst/verify_metrics}} system to facilitate the centralised definition of metrics, which we regard as a key step in the right direction.

\begin{recommendation}
    {rec:comp:metric:define:verifymetrics}
    {Formalise the \texttt{lsst.verify.metrics} system as the source of truth for metric definitions, by e.g. describing it in \citeds{LDM-503} and \citeds{LDM-639}}
    This should \textbf{not} be taken as a blanket endorsement of the current implementation of this system; \S\ref{sec:comp:metric:define} provides a number of recommendations as to the way that metrics are defined.
\end{recommendation}

\begin{recommendation}
    {rec:comp:metric:define:docs}
    {Provide a single, reliable set of documentation describing the metric definition system}
    In particular, mentions of old, obsolete packages\footnote{e.g. \texttt{lsst.validate.base}} should be expunged, and a clear set of introductory documentation should be provided which does not refer to informal technotes describing vaguely-specified design goals (\citeds{SQR-017, SQR-019}).
    In the process of developing this documentation, work closely with a named stakeholder in the Pipelines group to ensure that their needs are being adequately met; redesign of existing code may be necessary.
\end{recommendation}

Many metrics are defined as statistical aggregates of a per-source computed quantity --- for example, FWHM or shape --- over a defined selection of sources.
In order to enable a low-latency drill-down workflow and analyst flexibility, we recommend that for such metrics, the per-source computations be calculated and stored for \emph{all} sources, and that the selection and aggregation steps be logically separate.
For metrics computed in this way, the maximum storage granularity should be considered to be at the source level.

\begin{recommendation}
    {rec:comp:metric:define:compute}
    {The computation, selection, and aggregation steps that define a metric should be well compartmentalized}
\end{recommendation}

Other metrics may not be well-defined at the source level, such as the slope of the stellar locus in a given color-color space, or other similar metrics that require fitting a model to many sources at once.
Such metrics cannot follow this same compute--select--aggregate model, and will have a different maximum granularity (e.g., patch, tract, CCD, visit, or dataset).
This maximum granularity should be explicitly defined in the definition of the metric.

\begin{recommendation}
    {rec:sec:comp:metric:define:granularity}
    {Metric values should be stored with full granularity (source, CCD, patch, dataset)}
\end{recommendation}

Re-running pipelines to recompute metrics imposes a significant overhead to the analyst.
We therefore recommend that in general all computed metric values should be stored on disk at the highest relevant granularity.
In some cases these are per-source and may be included in the relevant object catalogs or in post-processed tables; in others, the minimum granularity may be at the CCD, patch, or even dataset levels.
This procedure provides the analyst the ability to filter metric values using arbitrary metadata (night, airmass, focal plane position, moon phase, etc) and re-aggregate to any level desired with any aggregation function (mean, median, percentiles, standard deviation, outliers, etc).
Supplemental storage of higher-level aggregates (e.g., mean FWHM by CCD) is discouraged because of duplication and loss of information, except where speed of visualization of \emph{key} quantities would be impaired due to the need to load large datasets.

We note that this procedure will result in a substantial increase in catalog volume.
We suggest that metric value storage therefore be configurable through the regular pipeline configuration system.
When working independently, developers may enable or disable at will depending on their use case; when running integration or other formalized tests, metrics will be stored for later analysis; metric storage when performing alert or data release processing is an operational decision.

``\Gls{tidy data}'' \citep{JSSv059i10} is recommended as a best practice for data analysis workflows, as it simplifies filter-groupby-aggregate workflows.

We expect that most analysts will be primarily interested in all values of a handful of metric columns at once, which suggests a column-store format will be optimal.
The potentially large number of metrics and metric values argues for storage on-disk with the output repository itself.
This isolation also facilitates ad-hoc processing \& QA workflows by individual analysts.

\begin{recommendation}
    {rec:sec:comp:metric:define:tidy}
    {Metric values should be stored as ``tidy data'' in columnar data stores (e.g., \gls{parquet}) as part an output data repository}
In particular, this should make it possible to load the data quickly enough for interactive work on hundreds of tracts or an equivalent number of visits.
\end{recommendation}

Additionally, we note that in order for interactive tools to be useful for visualizing results of large data repositories, the persistence model must allow for loading and aggregating metric values at the scale of tens to hundreds of tracts with low latency.
For example, if Parquet files are used to store tables of metric values, it would be preferable for such tables to be stored at the per-tract level instead of the per-patch level, to minimize I/O of small files when loading multiple tracts of data at once.

In order to facilitate joining and filtering metric values by other metadata, metric values should have appropriate Butler dataIds.

\begin{recommendation}
    {rec:sec:comp:metric:define:dataId}
    {Metric values should have Butler dataIds}
\end{recommendation}

As discussed in \S\ref{sec:comp:metric}, the appropriate time to calculate a metric value may depend on the nature of the metric.
Some are calculated and stored in real-time as pipeline execution continues; others may be handled by ``afterburner'' analysis of existing data repositories.
In either case, we suggest that close integration with the Data Butler is essential, and we believe the scheme presented here is compatible with the design of the ``Generation Three'' Butler.

\begin{recommendation}
    {rec:sec:comp:metric:define:butler}
    {It should be possible to use the Data Butler to persist and retrieve metric values}
\end{recommendation}

\subsubsection{Collecting metrics}
\label{sec:comp:metric:collect}

The SQuaRE team has also developed the \texttt{lsst.verify} package which enables the convenient packaging of metric values and submission to SQuaSH, the metric tracking dashboard (\S\ref{sec:comp:metric:dashboard}).

We have some concerns that adoption of this system has been slow.
In part, that might be due to it being developed relatively independently of ongoing work on the Science Pipelines and without substantial external input to or review of the design.
However, we believe that there are a small number of concrete steps which can be taken to address this.

\begin{recommendation}
    {rec:comp:metric:collect:verifypipe}
    {Develop clear guidelines for integrating metric collection with pipeline code}
    \citeds{DMTN-057} suggested a number of ways in which this might be done, but indecision has caused paralysis.
    The onus is on the Pipelines group to adopt one of these approaches (or develop an alternative)\footnote{Note \jira{DM-16016} in this context.}.
\end{recommendation}

\begin{recommendation}
    {rec:comp:metric:collect:adopt}
    {Pipelines leadership should start using the metric definition and collection system}
    As the above recommendations are met, this system will be usable.
    However, driving adoption will require proactive measures from pipelines Product Owners and T/CAMs.
\end{recommendation}

\subsubsection{Metric tracking: dashboard and alerts}
\label{sec:comp:metric:dashboard}

The \gls{squash} system, \citeds{SQR-009}, has been developed by the SQuaRE team to provide ``\gls{dashboard}'' functionality for metric tracking.
At its core, SQuaSH provides a database to which metric values may be submitted using the \texttt{lsst.verify} (\S\ref{sec:comp:metric:collect}) system, and a web-based service for displaying metric values as a time series.
This enables the user to track the evolution of metric values with time, and relate them directly to changes in code or configuration.
SQuaSH has also been designed to provide some limited ``drill-down'' functionality to explore the way in which high-level metrics have been calculated.

To date, SQuaSH has been used to follow a set of metrics derived from high-level LSST requirements and codified in the validate\_drp package.
It has been designed, though, to enable use by individual developers to track metrics which are of interest only to them, or relevant to a particular subset of the codebase on which they are working.

The Working Group feels that the major value in the SQuaSH system is in tracking and responding to regressions in performance (be they scientific or run-time) as the code evolves.
In this respect, it is in some ways analogous to the \gls{ci} system (\S\ref{sec:comp:ci}), and benefits from many of the same recommendations.

\begin{recommendation}
    {rec:comp:metric:dashboard:alert}
    {SQuaSH should issue alerts to developers and key stakeholders on regressions in important metric values}
    Key stakeholders should include:
    \begin{itemize}
      \item{Senior DM management (DM Project Manager, DM Subsystem Scientist, Pipelines Scientist, Science Pipelines T/CAMs and Science Leads);}
      \item{The developer who caused the regression, if it is possible to identify them (e.g. through commit logs).}
    \end{itemize}
    This will require careful design, as it may be in tension with the desire to enable developers to define arbitrary metrics for their own use: clearly, key stakeholders will not wish to be informed of every developer-defined metric which suffers a regression.
    We suggest that, for example, a ``subscription list'' for each metric be defined, and the key stakeholders automatically be added to it for all metrics deriving directly from high-level requirements.
\end{recommendation}

As with \texttt{lsst.verify}, we worry that there is confusion about how to distinguish metric values measured on different versions of the codebase, configurations, datasets, etc within the SQuaSH system.
For example, it is possible to define and track a metric on an algorithm implemented by code in the \texttt{lsst.pipe.tasks} package.
But that code may be run in multiple different contexts: as part of alert production, data release production, precovery, etc: how does SQuaSH distinguish between all of these environments?
We believe that SQuaSH is capable of this, but existing ``big picture'' documentation is lacking and hard to follow.

\begin{recommendation}
  {rec:comp:metric:dashboard:docs}
  {Provide a single, reliable source of documentation describing the SQuaSH system and a vision for its use in DM-wide metric tracking}
\end{recommendation}

We note that SQuaSH provides some drill-down capability to explore the source of metric values.
We suggest that this should not be the core business of SQuaSH, and prefer to consider a separate drill-down environment (\S\ref{sec:comp:drill}); further development of these capabilities within SQuaSH should not be prioritised.
However, if the metric submission system captures appropriate information, it would be desirable to enable SQuaSH to automatically spawn a copy of the drill-down system pointing at the repository corresponding to a particular metric value submission.

\begin{recommendation}
  {rec:comp:metric:dashboard:spawn}
  {The SQuaSH system should be closely coupled to the drill-down environment; in particular, the former should use the latter to enable drill-down functionality into particular metric values.}
\end{recommendation}

We recognize that developers may wish to submit results to SQuaSH from a variety of systems.
In particular, it must not be dependent upon a particular execution environment (e.g. Jenkins).

\begin{recommendation}
    {rec:comp:metric:dashboard:agnostic}
    {It must be possible to submit metrics to SQuaSH from arbitrary pipeline execution environments}
\end{recommendation}

When handling large datasets, there is value to tracking metric values computed over subsets of the whole.
For example, it may be more relevant to track how photometric repeatability varies over some patch, rather than over the whole sky.

\begin{recommendation}
    {rec:squash:dataId}
    {SQuaSH should be able to store and display metric values per DataId}
    For example, CCD, visit, patch, tract, filter.
\end{recommendation}
